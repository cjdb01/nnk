/*
 * Christopher Di Bella <chrisdb@cse.unsw.edu.au>
 *
 * 1 November, 2013
 *
 * som.h
 * The self-organising map implementation.
 *
 * Coding conventions documented in som.h.
 *
 * Note that this is a C++11 file, subject to GCC 4.7.2, as on the CSE machines
 *
 * Copyright (c) Christopher 2013, under the MIT License.
 * All rights reserved.
 */
 
namespace pipe
{
    /*
     * To save space, unused template parameters will be referred to by only the letters
     * that start each word. Template parameters that are actually used will have a meaningful
     * name instead of a shorthand equivalent.
     */
    template <typename T, typename Container = std::vector<T>>
    double euclidean_distance(const Container& x, const Container& y)
    {
        if (x.size() != y.size())
        {
            throw std::string("Vectors x and y are not the same size!");
        }
        
        double dist = 0;
        
        for (auto i = x.cbegin(), j = y.cbegin(); i != x.cend(); ++i, ++j)
        {
            dist += std::pow(i - j, 2);
        }
        
        return std::sqrt(dist);
    }
     
    template <typename IT, typename OT, unative_t IS, unative_t OSX, unative_t OSY>
    self_organising_map<IT, OT, IS, OSX, OSY>::self_organising_map(const double& init_lr, const double& lr_decay, const double& init_nbd, const double& nbd_decay) :
        m_rand(std::chrono::system_clock::now().time_since_epoch().count()), m_initialLR(init_lr), m_lrRateDecay(lr_decay), m_initialNbdWidth(init_nbd), m_nbdWidthDecay(nbd_decay)
    {
        m_rand.min(-rand_max/10);
        m_rand.max(rand_max/10);
    }

    template <typename IT, typename OT, unative_t IS, unative_t OSX, unative_t OSY>
    self_organising_map<IT, OT, IS, OSX, OSY>::self_organising_map(std::istream& in, const double& init_lr, const double& lr_decay, const double& init_nbd, const double& nbd_decay) :
        self_organising_map(init_lr, lr_decay, init_nbd, nbd_decay)
    {
        while (in.eof() == false)
        {
            m_input.push_back();
            m_weight.push_back();
            
            //std::for_each(m_input.back().begin(), m_input.back().end(), (std::array<IT, IS>::iterator& it)[&]{ in >> *it; in.get(); })
            
            for (auto it = m_input.back().begin() : m_input.back().end())
            {
                in >> *it;
                in.get();
            }
            
            for (auto it = m_input.back().begin() : m_input.back().end())
            {
                *it = small_random();
            }
        }
    }
    
    template <typename IT, typename OT, unative_t IS, unative_t OSX, unative_t OSY>
    double self_organising_map<IT, OT, IS, OSX, OSY>::small_random() const
    {
        return (static_cast<double>(m_rand())/rand_max);
    }
    
    template <typename IT, typename OT, unative_t InputSize, unative_t OSX, unative_t OSY>
    double self_organising_map<IT, OT, InputSize, OSX, OSY>::adjust_weight(const input_vector& x)
    {
        for (auto w = m_weight.back().begin(), x = m_input.cbegin(); w != m_weight.back().end(); ++w, ++x)
        {
            for (auto i = 0; i < InputSize; ++i)
            {
                (*w)[i] += m_learningRate * h() * (*x - (*w)[i]);
            }
        }
    }
    
    template <typename InputType, typename OT, unative_t InputSize, unative_t OSX, unative_t OSY>
    double self_organising_map<InputType, OT, InputSize, OSX, OSY>::h(const std::array<InputType, InputSize>& j) const
    {
        return std::exp(-std::pow(euclidean_distance(j, m_winningNeuron), 2) / (2 * std::pow(m_nbdWidth, 2)));
    }
    
    
}